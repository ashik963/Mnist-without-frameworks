{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import seed\n",
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--train TRAIN] [--trainlabel TRAINLABEL]\n",
      "                             [--test TEST] [--testlabel TESTLABEL] [--lr LR]\n",
      "                             [--epochs EPOCHS] [--n_x N_X] [--n_h1 N_H1]\n",
      "                             [--n_h2 N_H2] [--beta BETA]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "ipykernel_launcher.py: error: argument --train: invalid float value: 'train_image.csv'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# hyperparameters setting\n",
    "parser.add_argument('--train', type=float, default='train_image.csv', help='training image set')\n",
    "parser.add_argument('--trainlabel', type=float, default='train_label.csv', help='training label set')\n",
    "parser.add_argument('--test', type=float, default='test_image.csv', help='Testing image set')\n",
    "parser.add_argument('--testlabel', type=float, default='test_label.csv', help='Testing label set')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate')\n",
    "parser.add_argument('--epochs', type=int, default=50,\n",
    "                    help='number of epochs to train')\n",
    "parser.add_argument('--n_x', type=int, default=784, help='number of inputs')\n",
    "parser.add_argument('--n_h1', type=int, default=200,help='number of hidden units 1')\n",
    "parser.add_argument('--n_h2', type=int, default=100,help='number of hidden units 2')\n",
    "parser.add_argument('--beta', type=float, default=0.9,help='parameter for momentum')\n",
    "parser.add_argument('--batch_size', type=int,default=64, help='input batch size')\n",
    "\n",
    "# parse the arguments\n",
    "opt = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt:\n",
    "    n_x=784\n",
    "    n_h1=200\n",
    "    n_h2=100\n",
    "    lr=0.1\n",
    "    beta=0.9\n",
    "    batch_size=64\n",
    "    epochs=100\n",
    "opt=Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train_image.csv')\n",
    "train_label=pd.read_csv('train_label.csv')\n",
    "test_data=pd.read_csv('test_image.csv')\n",
    "test_label=pd.read_csv('test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('train_image.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ba694b1c574c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_image.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train_label.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_image.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[0;32m   2117\u001b[0m         rows = list(\n\u001b[0;32m   2118\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[1;32m-> 2119\u001b[1;33m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[0;32m   2120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m         rows = list(\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2117\u001b[0m         rows = list(\n\u001b[0;32m   2118\u001b[0m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[1;32m-> 2119\u001b[1;33m                   for (i, conv) in enumerate(converters)]))\n\u001b[0m\u001b[0;32m   2120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2121\u001b[0m         rows = list(\n",
      "\u001b[1;32mC:\\anaconda\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2116\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m         rows = list(\n\u001b[1;32m-> 2118\u001b[1;33m             zip(*[[conv._loose_call(_r) for _r in map(itemgetter(i), rows)]\n\u001b[0m\u001b[0;32m   2119\u001b[0m                   for (i, conv) in enumerate(converters)]))\n\u001b[0;32m   2120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data=genfromtxt('train_image.csv', delimiter=',')\n",
    "train_label=genfromtxt('train_label.csv', delimiter=',')\n",
    "test_data=genfromtxt('test_image.csv', delimiter=',')\n",
    "x_train=np.float32(train_data)\n",
    "x_test=np.float32(test_data)\n",
    "y_train = np.int32(train_label).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stack together for next step\n",
    "# X = np.vstack((x_train, x_test))\n",
    "# y = np.vstack((y_train, y_test))\n",
    "\n",
    "\n",
    "# one-hot encoding\n",
    "digits = 10\n",
    "examples = y_train.shape[0]\n",
    "y = y_train.reshape(1, examples)\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "\n",
    "\n",
    "# number of training set\n",
    "m = 60000\n",
    "# m_test = X.shape[0] - m\n",
    "# X_train, X_test = X[:m].T, X[m:].T\n",
    "# Y_train, Y_test = Y_new[:, :m], Y_new[:, m:]\n",
    "X_train, X_test = x_train.T, x_test.T\n",
    "Y_train = Y_new\n",
    "\n",
    "\n",
    "\n",
    "# shuffle training set\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "params = {\"W1\": np.random.randn(opt.n_h1, opt.n_x) * np.sqrt(1. / opt.n_x),\n",
    "          \"b1\": np.zeros((opt.n_h1, 1)) * np.sqrt(1. / opt.n_x),\n",
    "          \"W2\": np.random.randn(opt.n_h2, opt.n_h1) * np.sqrt(1. / opt.n_h1),\n",
    "          \"b2\": np.zeros((opt.n_h2, 1)) * np.sqrt(1. / opt.n_h1),\n",
    "          \"W3\": np.random.randn(digits, opt.n_h2) * np.sqrt(1. / opt.n_h2),\n",
    "          \"b3\": np.zeros((digits, 1)) * np.sqrt(1. / opt.n_h2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    sigmoid activation function.\n",
    "\n",
    "    inputs: z\n",
    "    outputs: sigmoid(z)\n",
    "    \"\"\"\n",
    "    s = 1. / (1. + np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross entropy loss\n",
    "def compute_loss(Y, Y_hat):\n",
    "    \"\"\"\n",
    "    compute loss function\n",
    "    \"\"\"\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1./m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, params):\n",
    "    \"\"\"\n",
    "    feed forward network: 2 - layer neural net\n",
    "\n",
    "    inputs:\n",
    "        params: dictionay a dictionary contains all the weights and biases\n",
    "\n",
    "    return:\n",
    "        cache: dictionay a dictionary contains all the fully connected units and activations\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "\n",
    "    # Z1 = W1.dot(x) + b1\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "\n",
    "    # A1 = sigmoid(Z1)\n",
    "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
    "    \n",
    "    # Z2 = W2.dot(x) + b2\n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
    "\n",
    "    # A2 = sigmoid(Z2)\n",
    "    cache[\"A2\"] = sigmoid(cache[\"Z2\"])\n",
    "\n",
    "    \n",
    "    # Z2 = W2.dot(A1) + b2\n",
    "    cache[\"Z3\"] = np.matmul(params[\"W3\"], cache[\"A2\"]) + params[\"b3\"]\n",
    "\n",
    "    # A2 = softmax(Z2)\n",
    "    cache[\"A3\"] = np.exp(cache[\"Z3\"]) / np.sum(np.exp(cache[\"Z3\"]), axis=0)\n",
    "\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(X, Y, params, cache, m_batch):\n",
    "    \"\"\"\n",
    "    back propagation\n",
    "\n",
    "    inputs:\n",
    "        params: dictionay a dictionary contains all the weights and biases\n",
    "        cache: dictionay a dictionary contains all the fully connected units and activations\n",
    "\n",
    "    return:\n",
    "        grads: dictionay a dictionary contains the gradients of corresponding weights and biases\n",
    "    \"\"\"\n",
    "    # error at last layer\n",
    "    dZ3 = cache[\"A3\"] - Y\n",
    "\n",
    "    # gradients at last layer (Py2 need 1. to transform to float)\n",
    "    dW3 = (1. / m_batch) * np.matmul(dZ3, cache[\"A2\"].T)\n",
    "    db3 = (1. / m_batch) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    \n",
    "    # back propgate through first layer\n",
    "    dA2 = np.matmul(params[\"W3\"].T, dZ3)\n",
    "    dZ2 = dA2 * sigmoid(cache[\"Z2\"]) * (1 - sigmoid(cache[\"Z2\"]))\n",
    "\n",
    "    # gradients at first layer (Py2 need 1. to transform to float)\n",
    "    dW2 = (1. / m_batch) * np.matmul(dZ2,  cache[\"A1\"].T)\n",
    "    db2 = (1. / m_batch) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # back propgate through first layer\n",
    "    dA1 = np.matmul(params[\"W2\"].T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "\n",
    "    # gradients at first layer (Py2 need 1. to transform to float)\n",
    "    dW1 = (1. / m_batch) * np.matmul(dZ1, X.T)\n",
    "    db1 = (1. / m_batch) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1, \"db1\": db1, \"dW2\": dW2, \"db2\": db2,\"dW3\": dW3, \"db3\": db3}\n",
    "\n",
    "    return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(opt.epochs):\n",
    "    seed(1234)\n",
    "    # shuffle training set\n",
    "    permutation = np.random.permutation(X_train.shape[1])\n",
    "    X_train_shuffled = X_train[:, permutation]\n",
    "    Y_train_shuffled = Y_train[:, permutation]\n",
    "\n",
    "    for j in range(opt.batch_size):\n",
    "\n",
    "        # get mini-batch\n",
    "        begin = j * opt.batch_size\n",
    "        end = min(begin + opt.batch_size, X_train.shape[1] - 1)\n",
    "        X = X_train_shuffled[:, begin:end]\n",
    "        Y = Y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "\n",
    "        # forward and backward\n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache, m_batch)\n",
    "\n",
    "        # with momentum (optional)\n",
    "        dW1 = (opt.beta * grads[\"dW1\"] + (1. - opt.beta) * grads[\"dW1\"])\n",
    "        db1 = (opt.beta * grads[\"db1\"] + (1. - opt.beta) * grads[\"db1\"])\n",
    "        dW2 = (opt.beta * grads[\"dW2\"] + (1. - opt.beta) * grads[\"dW2\"])\n",
    "        db2 = (opt.beta * grads[\"db2\"] + (1. - opt.beta) * grads[\"db2\"])\n",
    "        dW3 = (opt.beta * grads[\"dW3\"] + (1. - opt.beta) * grads[\"dW3\"])\n",
    "        db3 = (opt.beta * grads[\"db3\"] + (1. - opt.beta) * grads[\"db3\"])\n",
    "\n",
    "        # gradient descent\n",
    "        params[\"W1\"] = params[\"W1\"] - opt.lr * dW1\n",
    "        params[\"b1\"] = params[\"b1\"] - opt.lr * db1\n",
    "        params[\"W2\"] = params[\"W2\"] - opt.lr * dW2\n",
    "        params[\"b2\"] = params[\"b2\"] - opt.lr * db2\n",
    "        params[\"W3\"] = params[\"W3\"] - opt.lr * dW3\n",
    "        params[\"b3\"] = params[\"b3\"] - opt.lr * db3\n",
    "\n",
    "    # forward pass on training set\n",
    "    cache = feed_forward(X_train, params)\n",
    "    train_loss = compute_loss(Y_train, cache[\"A3\"])\n",
    "\n",
    "#     # forward pass on test set\n",
    "#     cache = feed_forward(X_test, params)\n",
    "#     test_loss = compute_loss(Y_test, cache[\"A3\"])\n",
    "    print(\"Epoch {}: training loss = {}\".format(\n",
    "        i + 1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = feed_forward(X_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,np.argmax(cache[\"A3\"],axis=0).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [7],\n",
       "       [0],\n",
       "       ...,\n",
       "       [4],\n",
       "       [8],\n",
       "       [6]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(cache[\"A3\"],axis=0).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv',np.int32(np.argmax(cache[\"A3\"],axis=0)).reshape(-1,1), delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         8\n",
       "0        7\n",
       "1        2\n",
       "2        1\n",
       "3        0\n",
       "4        4\n",
       "5        1\n",
       "6        4\n",
       "7        9\n",
       "8        6\n",
       "9        9\n",
       "10       0\n",
       "11       6\n",
       "12       9\n",
       "13       0\n",
       "14       1\n",
       "15       5\n",
       "16       9\n",
       "17       7\n",
       "18       3\n",
       "19       4\n",
       "20       9\n",
       "21       6\n",
       "22       6\n",
       "23       5\n",
       "24       4\n",
       "25       0\n",
       "26       7\n",
       "27       4\n",
       "28       0\n",
       "29       1\n",
       "...    ...\n",
       "9970     3\n",
       "9971     2\n",
       "9972     4\n",
       "9973     9\n",
       "9974     4\n",
       "9975     3\n",
       "9976     6\n",
       "9977     4\n",
       "9978     1\n",
       "9979     7\n",
       "9980     3\n",
       "9981     6\n",
       "9982     6\n",
       "9983     0\n",
       "9984     1\n",
       "9985     2\n",
       "9986     8\n",
       "9987     4\n",
       "9988     5\n",
       "9989     6\n",
       "9990     7\n",
       "9991     8\n",
       "9992     9\n",
       "9993     0\n",
       "9994     1\n",
       "9995     2\n",
       "9996     3\n",
       "9997     4\n",
       "9998     5\n",
       "9999     6\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
